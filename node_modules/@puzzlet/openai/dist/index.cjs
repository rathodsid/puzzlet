"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  OpenAIChatPlugin: () => OpenAIChatPlugin,
  default: () => src_default
});
module.exports = __toCommonJS(src_exports);

// src/openai-chat.ts
var import_openai = require("@ai-sdk/openai");
var OpenAIChatPlugin = class {
  constructor() {
    this.apiKey = "";
    this.provider = "openai";
  }
  setApiKey(apiKey) {
    this.apiKey = apiKey;
  }
  serialize(completionParams, name, api) {
    const { model, messages, tools, stream_options, tool_choice, ...settings } = completionParams;
    const frontMatterData = {
      name,
      metadata: {
        model: {
          name: model,
          settings: settings || {}
        }
      }
    };
    if (tools) {
      const transformedTools = tools.reduce((acc, { function: func }) => {
        acc[func.name] = {
          description: func.description,
          parameters: func.parameters
        };
        return acc;
      }, {});
      if (tool_choice === "auto") {
        frontMatterData.metadata.model.settings.tools = transformedTools;
      } else {
        const schemaTool = tools.find((tool) => tool.function.parameters);
        if (schemaTool) {
          frontMatterData.metadata.model.settings.schema = schemaTool.function.parameters;
        }
      }
    }
    const frontMatter = api.toFrontMatter(frontMatterData);
    const messageBody = messages.map((message) => {
      const role = message.role;
      const JSXTag = role.charAt(0).toUpperCase() + role.slice(1);
      return `<${JSXTag}>${message.content}</${JSXTag}>`;
    }).join("\n");
    return `${frontMatter}
${messageBody}`;
  }
  async deserialize(agentMark, api, config) {
    const { metadata, messages } = agentMark;
    const { model: modelConfig } = metadata;
    const completionParamsPromise = new Promise(
      async (resolve) => {
        const openai = (0, import_openai.createOpenAI)({
          compatibility: "strict",
          fetch: async (_, options) => {
            const requestBody = JSON.parse(options.body);
            resolve(requestBody);
            return new Response();
          }
        });
        const providerModel = openai(modelConfig.name);
        try {
          if (config == null ? void 0 : config.withStream) {
            await api.streamInference(modelConfig.settings, providerModel, messages);
          } else {
            await api.runInference(modelConfig.settings, providerModel, messages);
          }
        } catch (e) {
        }
      }
    );
    return completionParamsPromise;
  }
  async runInference(agentMark, api, options) {
    const apiKey = (options == null ? void 0 : options.apiKey) || this.apiKey || api.getEnv("OPENAI_API_KEY");
    if (!apiKey) {
      throw new Error("No API key provided");
    }
    const openai = (0, import_openai.createOpenAI)({
      compatibility: "strict",
      apiKey,
      fetch: api.fetch
    });
    const { metadata, messages } = agentMark;
    const { model: modelConfig } = metadata;
    const providerModel = openai(modelConfig.name);
    const result = await api.runInference(modelConfig.settings, providerModel, messages, options);
    return result;
  }
  async streamInference(agentMark, api, options) {
    const apiKey = (options == null ? void 0 : options.apiKey) || this.apiKey || api.getEnv("OPENAI_API_KEY");
    if (!apiKey) {
      throw new Error("No API key provided");
    }
    const openai = (0, import_openai.createOpenAI)({
      compatibility: "strict",
      apiKey,
      fetch: api.fetch
    });
    const { metadata, messages } = agentMark;
    const { model: modelConfig } = metadata;
    const providerModel = openai(modelConfig.name);
    const result = await api.streamInference(modelConfig.settings, providerModel, messages, options);
    return result;
  }
};

// src/index.ts
var src_default = OpenAIChatPlugin;
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  OpenAIChatPlugin
});
//# sourceMappingURL=index.cjs.map